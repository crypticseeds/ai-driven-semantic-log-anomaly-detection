services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: ai-log-postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-ailog}
      POSTGRES_USER: ${POSTGRES_USER:-ailog}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-changeme}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-ailog}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - ai-log-network

  # Kafka (KRaft mode - no Zookeeper)
  kafka:
    image: apache/kafka:3.7.0
    container_name: ai-log-kafka
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLUSTER_ID: ${KAFKA_CLUSTER_ID:-MkU3OEVBNTcwNTJENDM2Qk}
    ports:
      - "9092:9092"
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD-SHELL", "/opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092 > /dev/null 2>&1 || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 8
      start_period: 90s
    networks:
      - ai-log-network
    depends_on:
      - postgres

  # Fluent Bit (Log Forwarder)
  fluentbit:
    image: fluent/fluent-bit:3.0.0
    container_name: ai-log-fluentbit
    volumes:
      - ../ingestion/fluentbit/fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf:ro
      - ../ingestion/fluentbit/parsers.conf:/fluent-bit/etc/parsers.conf:ro
      - /var/log:/var/log:ro
    command: ["/fluent-bit/bin/fluent-bit", "-c", "/fluent-bit/etc/fluent-bit.conf"]
    networks:
      - ai-log-network
    depends_on:
      kafka:
        condition: service_healthy
    restart: unless-stopped

  # Backend (FastAPI)
  backend:
    build:
      context: ..
      dockerfile: infra/docker/backend.Dockerfile
    container_name: ai-log-backend
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER:-ailog}:${POSTGRES_PASSWORD:-changeme}@postgres:5432/${POSTGRES_DB:-ailog}
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
    ports:
      - "8000:8000"
    volumes:
      - ../backend:/app/backend
      - ../pyproject.toml:/app/pyproject.toml:ro
      - ../uv.lock:/app/uv.lock:ro
    networks:
      - ai-log-network
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
    restart: unless-stopped
    # Secrets are injected by Doppler CLI when running: doppler run -- docker-compose up
    # For CI/CD: doppler run --token=$DOPPLER_TOKEN -- docker-compose up
    working_dir: /app/backend
    command: uv run --frozen uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  # Dashboard (Next.js)
  # Commented out: Dashboard not yet initialized (missing package.json)
  # Uncomment once Next.js app is set up
  # dashboard:
  #   build:
  #     context: ..
  #     dockerfile: infra/docker/dashboard.Dockerfile
  #   container_name: ai-log-dashboard
  #   environment:
  #     NEXT_PUBLIC_API_URL: http://backend:8000
  #   ports:
  #     - "3000:3000"
  #   volumes:
  #     - ../dashboard/nextjs-app:/app
  #     - /app/node_modules
  #     - /app/.next
  #   networks:
  #     - ai-log-network
  #   depends_on:
  #     - backend

  # Prometheus (Metrics)
  prometheus:
    image: prom/prometheus:latest
    container_name: ai-log-prometheus
    volumes:
      - ../infra/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    ports:
      - "9090:9090"
    networks:
      - ai-log-network
    restart: unless-stopped

  # Grafana (Dashboards)
  grafana:
    image: grafana/grafana:latest
    container_name: ai-log-grafana
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin}
    volumes:
      - grafana_data:/var/lib/grafana
      - ../infra/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ../infra/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    ports:
      - "3001:3000"
    networks:
      - ai-log-network
    depends_on:
      - prometheus
    restart: unless-stopped

  # Tempo (Tracing)
  tempo:
    image: grafana/tempo:latest
    container_name: ai-log-tempo
    command: ["-config.file=/etc/tempo/tempo.yml"]
    volumes:
      - ../infra/tempo/tempo.yml:/etc/tempo/tempo.yml:ro
      - tempo_data:/var/tempo
    ports:
      - "4317:4317"  # OTLP gRPC
      - "4318:4318"  # OTLP HTTP
      - "3200:3200"  # Tempo
    networks:
      - ai-log-network
    restart: unless-stopped

  # Langfuse (LLM Observability)
  # Note: This docker image is included for self-contained deployment/testing.
  # For production, use Langfuse Cloud (credentials configured via Doppler).
  # Comment out this service if using Langfuse Cloud.
  # langfuse:
  #   image: langfuse/langfuse:latest
  #   container_name: ai-log-langfuse
  #   environment:
  #     DATABASE_URL: postgresql://${POSTGRES_USER:-ailog}:${POSTGRES_PASSWORD:-changeme}@postgres:5432/${POSTGRES_DB:-ailog}
  #     NEXTAUTH_SECRET: ${LANGFUSE_SECRET:-changeme}
  #     NEXTAUTH_URL: http://localhost:3002
  #     SALT: ${LANGFUSE_SALT:-changeme}
  #   ports:
  #     - "3002:3000"
  #   networks:
  #     - ai-log-network
  #   depends_on:
  #     postgres:
  #       condition: service_healthy

  # Ollama (Local LLM)
  # Commented out: Using OpenAI API instead (configured via Doppler)
  # Uncomment if you want to use local LLM instead of OpenAI
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ai-log-ollama
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   ports:
  #     - "11434:11434"
  #   networks:
  #     - ai-log-network
  #   # Note: Models need to be pulled after container starts
  #   # docker exec ai-log-ollama ollama pull llama3.1:8b

volumes:
  postgres_data:
  kafka_data:
  prometheus_data:
  grafana_data:
  tempo_data:
  # ollama_data:  # Uncomment if using Ollama service

networks:
  ai-log-network:
    driver: bridge

