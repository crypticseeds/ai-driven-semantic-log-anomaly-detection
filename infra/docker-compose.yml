services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: ai-log-postgres
    logging:
      driver: fluentd
      options:
        fluentd-address: ${HOST_IP:-host.docker.internal}:24224
        tag: docker.postgres
        fluentd-async: "true"
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-ailog}
      POSTGRES_USER: ${POSTGRES_USER:-ailog}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-changeme}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-ailog}" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - ai-log-network

  # Kafka (KRaft mode - no Zookeeper)
  kafka:
    image: apache/kafka:3.7.0
    container_name: ai-log-kafka
    logging:
      driver: fluentd
      options:
        fluentd-address: ${HOST_IP:-host.docker.internal}:24224
        tag: docker.kafka
        fluentd-async: "true"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093,EXTERNAL://0.0.0.0:9094
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,EXTERNAL://localhost:9094
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLUSTER_ID: ${KAFKA_CLUSTER_ID:-MkU3OEVBNTcwNTJENDM2Qk}
    ports:
      - "9092:9092"
      - "9094:9094"
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: [ "CMD-SHELL", "/opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092 > /dev/null 2>&1 || exit 1" ]
      interval: 15s
      timeout: 10s
      retries: 8
      start_period: 90s
    networks:
      - ai-log-network
    depends_on:
      - postgres
    restart: unless-stopped

  # Kafka Topics Initialization
  kafka-init:
    image: apache/kafka:3.7.0
    container_name: ai-log-kafka-init
    environment:
      KAFKA_BOOTSTRAP_SERVER: kafka:9092
    volumes:
      - ./kafka/init-topics.sh:/init-topics.sh:ro
    command: [ "/bin/bash", "/init-topics.sh" ]
    networks:
      - ai-log-network
    depends_on:
      kafka:
        condition: service_healthy
    restart: "no"

  # Kafbat UI (Kafka Management & Visualization)
  kafbat-ui:
    image: ghcr.io/kafbat/kafka-ui:latest
    container_name: ai-log-kafbat-ui
    logging:
      driver: fluentd
      options:
        fluentd-address: ${HOST_IP:-host.docker.internal}:24224
        tag: docker.kafbat-ui
        fluentd-async: "true"
    ports:
      - "8080:8080"
    environment:
      DYNAMIC_CONFIG_ENABLED: "true"
      KAFKA_CLUSTERS_0_NAME: "ai-log-kafka-cluster"
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: "kafka:9092"
    networks:
      - ai-log-network
    depends_on:
      kafka:
        condition: service_healthy
      kafka-init:
        condition: service_completed_successfully
    restart: unless-stopped

  # Fluent Bit (Log Forwarder)
  fluentbit:
    image: fluent/fluent-bit:3.0.0
    container_name: ai-log-fluentbit
    ports:
      - "24224:24224"
      - "24224:24224/udp"
    volumes:
      - ../infra/ingestion/fluentbit/fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf:ro
      - ../infra/ingestion/fluentbit/parsers.conf:/fluent-bit/etc/parsers.conf:ro
      - /var/log:/var/log:ro
      # Persist position tracking database across restarts
      - fluentbit_db:/fluent-bit/db
    command: [ "/fluent-bit/bin/fluent-bit", "-c", "/fluent-bit/etc/fluent-bit.conf" ]
    networks:
      - ai-log-network
    depends_on:
      kafka:
        condition: service_healthy
      kafka-init:
        condition: service_completed_successfully
    restart: unless-stopped

  # Backend (FastAPI)
  backend:
    build:
      context: ..
      dockerfile: infra/docker/backend.Dockerfile
    container_name: ai-log-backend
    logging:
      driver: fluentd
      options:
        fluentd-address: ${HOST_IP:-host.docker.internal}:24224
        tag: docker.backend
        fluentd-async: "true"
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER:-ailog}:${POSTGRES_PASSWORD:-changeme}@postgres:5432/${POSTGRES_DB:-ailog}
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      # OpenAI Configuration (injected by Doppler)
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      OPENAI_BUDGET: ${OPENAI_BUDGET:-}
      # Qdrant Configuration (injected by Doppler)
      QDRANT_URL: ${QDRANT_URL:-}
      QDRANT_API_KEY: ${QDRANT_API_KEY:-}
      # Sentry Configuration (injected by Doppler)
      SENTRY_DSN: ${SENTRY_DSN:-}
      # Langfuse Configuration (injected by Doppler)
      LANGFUSE_SECRET_KEY: ${LANGFUSE_SECRET_KEY:-}
      LANGFUSE_PUBLIC_KEY: ${LANGFUSE_PUBLIC_KEY:-}
      LANGFUSE_HOST: ${LANGFUSE_HOST:-http://langfuse:3000}
      # Debug mode for development (enables CORS regex for local network IPs)
      DEBUG: "true"
      # CORS configuration for local network access
      CORS_ORIGINS: '["http://localhost:3000","http://localhost:3001","http://127.0.0.1:3000","http://127.0.0.1:3001","http://0.0.0.0:3000","http://0.0.0.0:3001"]'
    ports:
      - "8000:8000"
    volumes:
      - ../backend:/app/backend
      - ../pyproject.toml:/app/pyproject.toml:ro
      - ../uv.lock:/app/uv.lock:ro
    networks:
      - ai-log-network
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
      kafka-init:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    # Secrets are injected by Doppler CLI when running: doppler run -- docker-compose up
    # For CI/CD: doppler run --token=$DOPPLER_TOKEN -- docker-compose up
    working_dir: /app/backend
    command: uv run --frozen uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  # Dashboard (Next.js)
  # Commented out: Dashboard not yet initialized (missing package.json)
  # Uncomment once Next.js app is set up
  # dashboard:
  #   build:
  #     context: ..
  #     dockerfile: infra/docker/dashboard.Dockerfile
  #   container_name: ai-log-dashboard
  #   environment:
  #     NEXT_PUBLIC_API_URL: http://backend:8000
  #   ports:
  #     - "3000:3000"
  #   volumes:
  #     - ../dashboard/nextjs-app:/app
  #     - /app/node_modules
  #     - /app/.next
  #   networks:
  #     - ai-log-network
  #   depends_on:
  #     - backend

  # Prometheus (Metrics)
  prometheus:
    image: prom/prometheus:latest
    container_name: ai-log-prometheus
    logging:
      driver: fluentd
      options:
        fluentd-address: ${HOST_IP:-host.docker.internal}:24224
        tag: docker.prometheus
        fluentd-async: "true"
    volumes:
      - ../infra/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    ports:
      - "9090:9090"
    networks:
      - ai-log-network
    restart: unless-stopped

  # Grafana (Dashboards)
  grafana:
    image: grafana/grafana:latest
    container_name: ai-log-grafana
    logging:
      driver: fluentd
      options:
        fluentd-address: ${HOST_IP:-host.docker.internal}:24224
        tag: docker.grafana
        fluentd-async: "true"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin}
    volumes:
      - grafana_data:/var/lib/grafana
      - ../infra/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ../infra/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    ports:
      - "3001:3000"
    networks:
      - ai-log-network
    depends_on:
      - prometheus
    restart: unless-stopped

  # Tempo (Tracing)
  tempo:
    image: grafana/tempo:latest
    container_name: ai-log-tempo
    logging:
      driver: fluentd
      options:
        fluentd-address: ${HOST_IP:-host.docker.internal}:24224
        tag: docker.tempo
        fluentd-async: "true"
    command: [ "-config.file=/etc/tempo/tempo.yml" ]
    volumes:
      - ../infra/tempo/tempo.yml:/etc/tempo/tempo.yml:ro
      - tempo_data:/var/tempo
    ports:
      - "4317:4317" # OTLP gRPC
      - "4318:4318" # OTLP HTTP
      - "3200:3200" # Tempo
    networks:
      - ai-log-network
    restart: unless-stopped
  # Langfuse (LLM Observability)
  # Note: This docker image is included for self-contained deployment/testing.
  # For production, use Langfuse Cloud (credentials configured via Doppler).
  # Comment out this service if using Langfuse Cloud.
  # langfuse:
  #   image: langfuse/langfuse:latest
  #   container_name: ai-log-langfuse
  #   environment:
  #     DATABASE_URL: postgresql://${POSTGRES_USER:-ailog}:${POSTGRES_PASSWORD:-changeme}@postgres:5432/${POSTGRES_DB:-ailog}
  #     NEXTAUTH_SECRET: ${LANGFUSE_SECRET:-changeme}
  #     NEXTAUTH_URL: http://localhost:3002
  #     SALT: ${LANGFUSE_SALT:-changeme}
  #   ports:
  #     - "3002:3000"
  #   networks:
  #     - ai-log-network
  #   depends_on:
  #     postgres:
  #       condition: service_healthy

  # Ollama (Local LLM)
  # Commented out: Using OpenAI API instead (configured via Doppler)
  # Uncomment if you want to use local LLM instead of OpenAI
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ai-log-ollama
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   ports:
  #     - "11434:11434"
  #   networks:
  #     - ai-log-network
  #   # Note: Models need to be pulled after container starts
  #   # docker exec ai-log-ollama ollama pull llama3.1:8b

volumes:
  postgres_data:
  kafka_data:
  prometheus_data:
  grafana_data:
  tempo_data:
  fluentbit_db:
    # ollama_data:  # Uncomment if using Ollama service

networks:
  ai-log-network:
    driver: bridge
